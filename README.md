## Chenfei WU (吴晨飞)

[Microsoft Research](https://www.microsoft.com/en-us/research/people/chewu/) \| [Google Scholar](https://scholar.google.com/citations?hl=zh-CN&user=1YlFL5UAAAAJ)

Dr. Chenfei Wu is a senior researcher at Microsoft Research Asia. His research focuses on large-scale pre-training, multimodal understanding, and generation. His main research includes a series of multimodal generation models NUWA (NUWA, NUWA-LIP, NUWA-Infinity, NUWA-3D, NUWA-XL), a series of multimodal understanding models (KD-VLP, Bridge-Tower), and multimodal dialogue systems (Visual ChatGPT, TaskMatrix.AI). He published several papers in conferences such as CVPR, NeurIPS, ACL, ECCV, AAAI, MM.

吴晨飞博士，微软亚洲研究院高级研究员。研究方向为大模型预训练、多模态理解和生成。主要研究工作包括多模态生成模型 NUWA（女娲）系列（NUWA, NUWA-LIP, NUWA-Infinity, NUWA-3D, NUWA-XL）、多模态理解模型 Bridge Tower（桥塔）系列（KD-VLP, Bridge-Tower）以及多模态对话系统（Visual ChatGPT, TaskMatrix.AI）。在 CVPR, NeurIPS, ACL, ECCV, AAAI, MM 等会发表多篇论文。

### Highlight

- **Multimodal generation**: [GODIVA](https://arxiv.org/abs/2104.14806) (Preprint, 2021), [NUWA(女娲)](https://arxiv.org/abs/2111.12417) (ECCV, 2022), [NUWA-Infinity](https://arxiv.org/abs/2207.09814) (NeurIPS, 2022), [NUWA-LIP](https://arxiv.org/abs/2202.05009) (CVPR 2023), [NUWA-3D](https://arxiv.org/abs/2302.10781) (IJCAI 2023), [NUWA-XL](https://arxiv.org/abs/2303.12346) (ACL 2023), [DragNUWA](https://arxiv.org/abs/2308.08089).
- **Multimodal understanding**: [Bridge-Tower](https://arxiv.org/abs/2206.08657) (AAAI, 2023), [Manager-Tower]() (ACL, 2023)
- **Multimodal system**: [Visual ChatGPT](https://arxiv.org/abs/2303.04671) (Arxiv), [TaskMatrix.AI](https://arxiv.org/abs/2303.16434) (Arxiv)
- **Multimodal visualization**: [VL-InterpreT](https://openaccess.thecvf.com/content/CVPR2022/papers/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.pdf) (CVPR, 2022).

### Talks

- [NUWA: Neural visual world creation with multimodal pretraining](https://www.microsoft.com/en-us/research/video/research-talk-nuwa-neural-visual-world-creation-with-multimodal-pretraining/). Microsoft Research Summit 2021, October 2021.
- [VLP for Text-to-Image Synthesis](https://www.microsoft.com/en-us/research/video/vlp-tutorial-cvpr-2022-vlp-for-text-to-image-synthesis/). VLP Tutorial @ CVPR 2022, June 2022.

### Publication

- **Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2303.04671) [![](https://img.shields.io/github/stars/chenfei-wu/TaskMatrix?style=social&label=Github+Stars)](https://github.com/chenfei-wu/TaskMatrix)
  <br> **Chenfei Wu**, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan.
  <br> arXiv, 2023.

- **Nüwa: Visual synthesis pre-training for neural visual world creation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://link.springer.com/chapter/10.1007/978-3-031-19787-1_41) [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)
  <br> **Chenfei Wu**, Jian Liang, Lei Ji, Fan Yang, Yuejian Fang, Daxin Jiang, Nan Duan.
  <br> ECCV, 2022.

- **Godiva: Generating open-domain videos from natural descriptions**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2104.14806)
  <br> **Chenfei Wu**, Lun Huang, Qianxi Zhang, Binyang Li, Lei Ji, Fan Yang, Guillermo Sapiro, Nan Duan.
  <br> Arxiv, 2021

- **Taskmatrix. ai: Completing tasks by connecting foundation models with millions of apis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2303.16434) [![](https://img.shields.io/github/stars/chenfei-wu/TaskMatrix?style=social&label=Github+Stars)](https://github.com/chenfei-wu/TaskMatrix)
  <br> Yaobo Liang, **Chenfei Wu**, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, Nan Duan.
  <br> Intelligent Computing, 2024

- **Object-difference attention: A simple relational attention for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://dl.acm.org/doi/abs/10.1145/3240508.3240513)
  <br> **Chenfei Wu**, Jinlai Liu, Xiaojie Wang, Xuan Dong
  <br> ACM Multimedia, 2018

- **Chain of reasoning for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://proceedings.neurips.cc/paper_files/paper/2018/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html)
  <br> **Chenfei Wu**, Jinlai Liu, Xiaojie Wang, Xuan Dong.
  <br> NeurIPS, 2018

- **Reco: Region-controlled text-to-image generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_ReCo_Region-Controlled_Text-to-Image_Generation_CVPR_2023_paper.html) [![](https://img.shields.io/github/stars/microsoft/ReCo?style=social&label=Github+Stars)](https://github.com/microsoft/ReCo)
  <br> Zhengyuan Yang, Jianfeng Wang, Zhe Gan, Linjie Li, Kevin Lin, **Chenfei Wu**, Nan Duan, Zicheng Liu, Ce Liu, Michael Zeng, Lijuan Wang.
  <br> CVPR, 2023.

- **Differential networks for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://ojs.aaai.org/index.php/AAAI/article/view/4930)
  <br>**Chenfei Wu**, Jinlai Liu, Xiaojie Wang, Ruifan Li.
  <br> AAAI, 2019.

- **Bridgetower: Building bridges between encoders in vision-language representation learning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://ojs.aaai.org/index.php/AAAI/article/view/26263) [![](https://img.shields.io/github/stars/microsoft/BridgeTower?style=social&label=Github+Stars)](https://github.com/microsoft/BridgeTower)
  <br> Xiao Xu, **Chenfei Wu**, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.
  <br> AAAI 2023.

- **NUWA-XL: Diffusion over diffusion for extremely long video generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2303.12346) [![](https://img.shields.io/badge/Homepage-FF8E8F)](https://nuwa-infinity.microsoft.com/#/NUWAXL) [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)
  <br> Shengming Yin, **Chenfei Wu**, Huan Yang, Jianfeng Wang, Xiaodong Wang, Minheng Ni, Zhengyuan Yang, Linjie Li, Shuguang Liu, Fan Yang, Jianlong Fu, Gong Ming, Lijuan Wang, Zicheng Liu, Houqiang Li, Nan Duan.
  <br> ACL 2023.

- **Dragnuwa: Fine-grained control in video generation by integrating text, image, and trajectory**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2308.08089) [![](https://img.shields.io/badge/Homepage-FF8E8F)](https://nuwa-infinity.microsoft.com/#/) [![](https://img.shields.io/github/stars/ProjectNUWA/DragNUWA?style=social&label=Github+Stars)](https://github.com/ProjectNUWA/DragNUWA)
  <br> Shengming Yin, **Chenfei Wu**, Jian Liang, Jie Shi, Houqiang Li, Gong Ming, Nan Duan.
  <br> Arxiv 2023.

- **NUWA-Infinity: Autoregressive over autoregressive generation for infinite visual synthesis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6358cd0cd6607fdf4870595795eb1710-Abstract-Conference.html) [![](https://img.shields.io/badge/Homepage-FF8E8F)](https://nuwa-infinity.microsoft.com/#/NUWAInfinity) [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)
  <br> Jian Liang, **Chenfei Wu**, Xiaowei Hu, Zhe Gan, Jianfeng Wang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan.
  <br> CVPR 2022.

- **Vl-interpret: An interactive visualization tool for interpreting vision-language transformers**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openaccess.thecvf.com/content/CVPR2022/html/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.html)
  <br> Estelle Aflalo, Meng Du, Shao-Yen Tseng, Yongfei Liu, **Chenfei Wu**, Nan Duan, Vasudev Lal.
  <br> CVPR 2022.

- **Kd-vlp: Improving end-to-end vision-and-language pretraining with object knowledge distillation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2109.10504)
  <br> Yongfei Liu, Chenfei Wu, Shao-yen Tseng, Vasudev Lal, Xuming He, Nan Duan.
  <br> Findings of NAACL, 2022.

- **Low-code llm: Visual programming over llms**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2304.08103)
  <br> Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge, **Chenfei Wu**, Wang You, Ting Song, Yan Xia, Jonathan Tien, Nan Duan.
  <br> Arxiv 2023.

- **Divae: Photorealistic images synthesis with denoising diffusion decoder**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2206.00386)
  <br> Jie Shi, **Chenfei Wu**, Jian Liang, Xiang Liu, Nan Duan.
  <br> Arxiv 2022.

- **Learning to program with natural language**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2304.10464)
  <br> Yiduo Guo, Yaobo Liang, **Chenfei Wu**, Wenshan Wu, Dongyan Zhao, Nan Duan.
  <br> Arxiv 2023.

- **NUWA-LIP: language-guided image inpainting with defect-free VQGAN**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2202.05009)
  <br> Minheng Ni, **Chenfei Wu**, Haoyang Huang, Daxin Jiang, Wangmeng Zuo, Nan Duan.
  <br> CVPR 2023.

- **GEM: A general evaluation benchmark for multimodal tasks**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2106.09889)
  <br> Lin Su, Nan Duan, Edward Cui, Lei Ji, **Chenfei Wu**, Huaishao Luo, Yongfei Liu, Ming Zhong, Taroon Bharti, Arun Sacheti.
  <br> Findings of ACL, 2021.

- **Learning temporal video procedure segmentation from an automatically collected large dataset**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openaccess.thecvf.com/content/WACV2022/html/Ji_Learning_Temporal_Video_Procedure_Segmentation_From_an_Automatically_Collected_Large_WACV_2022_paper.html)
  <br> Lei Ji, **Chenfei Wu**, Daisy Zhou, Kun Yan, Edward Cui, Xilin Chen, Nan Duan.
  <br> WACV 2022.

- **Deep reason: A strong baseline for real-world visual reasoning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/1905.10226)
  <br> **Chenfei Wu**, Yanzhao Zhou, Gen Li, Nan Duan, Duyu Tang, Xiaojie Wang.
  <br> CVPR VQA Workshop, 2019.

- **EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2310.08185)
  <br> Wang You, Wenshan Wu, Yaobo Liang, Shaoguang Mao, **Chenfei Wu**, Maosong Cao, Yuzhe Cai, Yiduo Guo, Yan Xia, Furu Wei, Nan Duan.
  <br> Arxiv 2023.

- **ORES: Open-vocabulary Responsible Visual Synthesis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2308.13785)
  <br> Minheng Ni, **Chenfei Wu**, Xiaodong Wang, Shengming Yin, Lijuan Wang, Zicheng Liu, Nan Duan.
  <br> AAAI 2024.

- **ManagerTower: Aggregating the insights of uni-modal experts for vision-language representation learning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://aclanthology.org/2023.acl-long.811/)
  <br> Xiao Xu, Bei Li, **Chenfei Wu**, Shao-Yen Tseng, Anahita Bhiwandiwalla, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.
  <br> ACL 2023.

- **Sequential visual reasoning for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://ieeexplore.ieee.org/abstract/document/8691361/)
  <br> Jinlai Liu, Chenfei Wu, Xiaojie Wang, Xuan Dong.
  <br> CCIS 2018.

- **Using Left and Right Brains Together: Towards Vision and Language Planning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2402.10534)
  <br> Jun Cen, Chenfei Wu, Xiao Liu, Shengming Yin, Yixuan Pei, Jinglong Yang, Qifeng Chen, Nan Duan, Jianguo Zhang.
  <br> Arxiv 2024.

- **GameEval: Evaluating LLMs on Conversational Games**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2402.10534)
  <br> Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, Nan Duan.
  <br> Arxiv 2023.

- **StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2401.17093)
  <br> Zecheng Tang, **Chenfei Wu**, Zekai Zhang, Mingheng Ni, Shengming Yin, Yu Liu, Zhengyuan Yang, Lijuan Wang, Zicheng Liu, Juntao Li, Nan Duan.
  <br> Arxiv 2024.

- **LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openreview.net/forum?id=qCUWVT0Ayy) [![](https://img.shields.io/github/stars/ProjectNUWA/LayoutNUWA?style=social&label=Github+Stars)](https://github.com/ProjectNUWA/LayoutNUWA)
  <br> Zecheng Tang, **Chenfei Wu**, Juntao Li, Nan Duan.
  <br> ICLR 2024.

- **NUWA-3D: Learning 3D photography videos via self-supervised diffusion on single images**. [![](https://img.shields.io/badge/Paper-378CE7)](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/167)
  <br> Xiaodong Wang, **Chenfei Wu**, Shengming Yin, Minheng Ni, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan.
  <br> IJCAI 2023.

- **HORIZON: A High-Resolution Panorama Synthesis Framework**. [![](https://img.shields.io/badge/Paper-378CE7)](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/167)
  <br> Kun Yan, Lei Ji, **Chenfei Wu**, Jian Liang, Ming Zhou, Nan Duan, Shuai Ma.
  <br> AAAI 2024.

- **Trace Controlled Text to Image Generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://link.springer.com/chapter/10.1007/978-3-031-20059-5_4)
  <br> Kun Yan, Lei Ji, Chenfei Wu, Jianmin Bao, Ming Zhou, Nan Duan, Shuai Ma.
  <br> ECCV, 2022.
